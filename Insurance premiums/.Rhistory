isZipcode("dasdas")
isZipcode("dasdas1234")
isZipcode("dasdas12345")
isZipcode<-function(x){
grep("^\\d{5}$",x)
}
isZipcode("dasdas12345")
isZipcode("06250")
isZipcode("0")
isZipcode("00000")
gsub("[a-zA-Z0-9.+-_]+@([a-zZ-A0-9.-]+\\.[a-zA-Z]{2,63})","\\1",
"haoxi.ma@uconn.edu")
gsub("[a-zA-Z0-9.+-_]+@([a-zA-Z0-9.-]+\\.[a-zA-Z]{2,63})","\\1",
"haoxi.ma@uconn.edu")
gsub("[a-zA-Z0-9.+-_]+@([a-zA-Z0-9.-]+\\.[a-zA-Z]{2,63})","\\2",
"haoxi.ma@uconn.edu")
gsub("([a-zA-Z0-9.+-_])+@([a-zA-Z0-9.-]+\\.[a-zA-Z]{2,63})","\\1",
"haoxi.ma@uconn.edu")
gsub("([a-zA-Z0-9.+-_]*)+@([a-zA-Z0-9.-]+\\.[a-zA-Z]{2,63})","\\1",
"haoxi.ma@uconn.edu")
gsub("([a-zA-Z0-9.+-_]*)+@([a-zA-Z0-9.-]+\.[a-zA-Z]{2,63})","\\2",
"haoxi.ma@uconn.edu")
gsub("([a-zA-Z0-9.+-_]*)+@([a-zA-Z0-9.-]+\\.[a-zA-Z]{2,63})","\\2",
"haoxi.ma@uconn.edu")
gsub("([a-zA-Z0-9.+-_]*)+@([a-zA-Z0-9.-]+\.[a-zA-Z]{2,63})","\\2",
"haoxi.ma@uconn.edu")
gsub('([a-zA-Z0-9.+-_]*)+@([a-zA-Z0-9.-]+\.[a-zA-Z]{2,63})',"\\2",
"haoxi.ma@uconn.edu")
gsub("([a-zA-Z0-9.+-_]*)+@([a-zA-Z0-9.-]+\\.[a-zA-Z]{2,63})","\\2",
"haoxi.ma@uconn.edu")
gsub("([a-zA-Z0-9.+-_]*)+@([a-zA-Z0-9.-]+.[a-zA-Z]{2,63})","\\2",
"haoxi.ma@uconn.edu")
gsub("([a-zA-Z0-9.+-_]*)+@([a-zA-Z0-9.-]+\.[a-zA-Z]{2,63})","\\2",
"haoxi.ma@uconn.edu")
gsub("([a-zA-Z0-9.+-_]*)+@([a-zA-Z0-9.-]+\\.[a-zA-Z]{2,63})","\\2",
"haoxi.ma@uconn.edu")
gsub("([a-zA-Z0-9.+-_]*)+@([a-zA-Z0-9.-]+.[a-zA-Z]{2,63})","\\2",
"haoxi.ma@uconn.edu")
gsub("([a-zA-Z0-9.+-_]*)+@([a-zA-Z0-9.-]+\\.[a-zA-Z]{2,63})","\\2",
"haoxi.ma@.edu")
gsub("([a-zA-Z0-9.+-_]*)+@([a-zA-Z0-9.-]+\\.[a-zA-Z]{2,63})","\\1",
"haoxi.ma@.edu")
grep("([a-zA-Z0-9.+-_])+@([a-zA-Z0-9.-]+\\.[a-zA-Z]{2,63})",
"haoxi.ma@.edu")
grep("([a-zA-Z0-9.+-_])+@([a-zA-Z0-9.-]+\\.[a-zA-Z]{2,63})",
"haoxi.ma@uconn.edu")
grep("([a-zA-Z0-9.+-_])+@([a-zA-Z0-9.-]+.[a-zA-Z]{2,63})",
"haoxi.ma@uconn.edu")
grep("([a-zA-Z0-9.+-_])+@([a-zA-Z0-9.-]+.[a-zA-Z]{2,63})",
"haoxi.ma@uconnedu")
grep("([a-zA-Z0-9.+-_])+@([a-zA-Z0-9.-]+.[a-zA-Z]{2,63})",
"haoxi.ma@uconnedu")
grep("([a-zA-Z0-9.+-_])+@([a-zA-Z0-9.-]+\.[a-zA-Z]{2,63})",
"haoxi.ma@uconnedu")
grep("([a-zA-Z0-9.+-_])+@([a-zA-Z0-9.-]+\\.[a-zA-Z]{2,63})",
"haoxi.ma@uconnedu")
1-exp(-2/3)
pf(1,1,1)
pnorm(0)
pnorm(0,0,1)
pexp(4,1/6)
1-pexp(4,1/2)
exp(-2)
pgamma(7,2,6)
pgamma(7,2,1\6)
pgamma(4,1,6)
pgamma(4,1,1/6)
pgamma(7,2,1/6)
1-pgamma(7,2,1/2)
3.4*3
pgamma(10.2,3,1/6)
1-pgamma(10.2,3,1/2)
2.8*4
pgamma(11.2,4,1/6)
1-pgamma(11.2,4,1/2)
qchisq(0.95,1)
exp(1.0986)
1-pchisq(8.4982,1)
1-pchisq(35.5784,21)
exp(0.1743)
qnorm
qnorm(0.025)
0.1743+1.96*c(-0.0231,0.0231)
mhx<-0.1743+1.96*c(-0.0231,0.0231)
exp(mhx)
1.7839^2
2467.16+2.14+119.3+5.71+17.69
2467.16+2.14
2467.16+2.14+119.3
2467.16+2.14+119.3+5.71
2612-2467.16
2612-2469.3
2612-2588.6
2612-2594.31
17.69+5.71
10*log(2612/10)+2
log(261.2)
log(261.2)*10
10*log(144.84/10)+2*2
10*log(142.7/10)+2*3
〖AIC〗_4=10*log(23.4/10)+2*4
10*log(23.4/10)+2*4
10*log(17.69/10)+2*5
10*log(23.4/10)+2*4
10*log(17.69/10)+2*5
17.69/5
2612/3.54-(10-2)
2612/3.54
737.8531-8
144.84/3.54-(10-2*2)
142.7/3.54-(10-2*3)
23.4/3.54-(10-2*4)
17.69/3.54-(10-2*5)
1.92/(1-0.44)
1-0.44
1.92/0.56
0.7/(1-0.71)
0.14/(1-0.25)
(-2.37)/(1-0.52)
(-0.01)/(1-0.12)
(-1.46)/(1-0.33)
0.75/(1-0.51)
(-1.1)/(1-0.38)
1.92/(1-0.24)
(-0.5)/(1-0.5)
x<-3.428571^2+2.413793^2+0.1866667^2+-4.9375^2
-4.9375^2
x<-3.428571^2+2.413793^2+0.1866667^2+(-4.9375)^2+(-0.01136364)^2
(-4.9375)^2
x<-3.428571^2+2.413793^2+0.1866667^2+(-4.9375)^2+(-0.01136364)^2+(-2.179104)^2+1.530612^2+(-1.774194)^2+2.526316^2+1
x
2.3-3.5
1.7-3.5
1.2-1.6
0.9-1.6
15+10+20
106.984-75.787
106.984-67.442
31+6.5+1.75
1-pchisq(39.542,4)
exp(1.33)
8.95918^2
80.27+64.38+2*-15.47+9*58.78+6*-3.28+6*8.28
(-47.17882-1.07436+3*16.96087)/√672.73
(-47.17882-1.07436+3*16.96087)/sqrt(672.73)
-47.17882-1.07436+3*16.96087
sqrt(672.73)
1-pt(abs(0.1013774),55)
2*(1-pt(abs(0.1013774),55))
0.90565-1.07436+10.82241*0.02+16.96087*0.1
ex pa(1.743825)
exp((1.743825)
exp(1.743825)
69.249-67.442
0.0566+1.7506
1-pchisq(1.807,2)
67.442/55
sqrt(0.27)
sqrt(0.28)
0.7004/0.5196152
(-0.5881)/0.5291503
1.1843/0.5291503
1-pt(1.347921,27)
2*(1-pt(1.347921,27))
2*(1-pt(1.111404,27))
2*(1-pt(2.238116,27))
41.054-33.672
1-pchisq(7.382,2)
30/100
0.7004-0.5881*0.3+1.1843*0.5
0.3^2*0.28+0.5^2*0.28+2*0.3*0.5*-0.04
0.09*0.28+0.25*0.28+0.6*0.5*-0.04
qnorm(0.1)
qnorm(0.25)
qnorm(0.025)
qnorm(0.05)
sqrt(0.0832)
1.11612-1.64*0.2884441
1.11612+1.64*0.2884441
1/(1/0.6430717+1)
1/0.6430717
1/2.555
1/(1/1.589168+1)
1-0.3913894
1-0.6137755
30-17
10/17
9/13
17*13
13+5+11+6+13+13+5+13+13+6+6+7+13+7+13+13+13
8+2+7+8+7+7+6+6
17*13
221-170-51
170/221
(-47.17882-1.07436+3*16.96087)/sqrt(672.73)
2*(1-pnorm(0.1013774,0,1))
2*(1-pnorm(0.1013774))
2(1-pnorm(1.347921))
2*(1-pnorm(1.347921))
2*(1-pnorm(1.111404))
2*(1-pnorm(2.238116))
0.6430717/(1+0.6430717)
pnorm(2.698)
1-pnorm(2.698)
1-0.003487872*2
ppoints(3)
1-0.5/3
0.5/3
qnorm(0.05)
qnorm(0.025)
#这个是wilcoxon signed rank test，有tied所以有warning
wilcox.test(stayhome,goabroad,alternative = "two.sided")
#####Q3
###a
twins<-read.csv("~/Desktop/5505/homework10/xid-48104659_1.dat",sep="")
stayhome<-twins$Sample1
goabroad<-twins$Sample2
#这个是wilcoxon signed rank test，有tied所以有warning
wilcox.test(stayhome,goabroad,alternative = "two.sided")
#这个是wilcoxon signed rank test，有tied所以有warning
wilcox.test(stayhome,goabroad,alternative = "two.sided",correct=FALSE)
vector("list",2)
matrix(0,10,2)
library(MASS)
#######neural network
library(neuralnet)
setwd("/Users/mahaoxi/Desktop/competition/Useful dataset")
library(dplyr)     ##to do some data manipulation
library(data.table)##to read/write data in a fast way
#Import dataset
final<-fread('dataset_MODEL1.csv')
# Set Seed so that same sample can be reproduced in future also
set.seed(1234)
# Now Selecting 75% of data as sample from total 'n' rows of the data
sample <- sample.int(n = nrow(final), size = floor(.75*nrow(final)), replace = F)
train <- final[sample, ]
test  <- final[-sample, ]
write.csv(train,"train.csv")
write.csv(test,"test.csv")
train<-read.csv("train.csv")
test<-read.csv("test.csv")
py.train<-train[,c(5,4,6:18,21)]
py.test<-test[,c(5,4,6:18,21)]
#######neural network
library(neuralnet)
maxs <- apply(py.train[,c(2:16)], 2, max)
mins <- apply(py.train[,c(2:16)], 2, min)
data_scaled <- as.data.frame(scale(py.train[,c(2:16)], center = mins, scale = maxs - mins))
ner_scaled<-cbind(py.train$Adjusted.death_rate,data_scaled)
names(ner_scaled)[1]<-"Adjusted.death_rate"
data_scaled_test<- as.data.frame(scale(py.test[,c(2:16)], center = mins, scale = maxs - mins))
ner_scaled_test<-cbind(py.test$Adjusted.death_rate,data_scaled_test)
n<-names(ner_scaled)
f<-as.formula(paste("Adjusted.death_rate~",paste(n[!n %in% c("Adjusted.death_rate")],collapse="+")))
#choose different stopping criteria for nn
threshold<-seq(10,250,10)
R_square_train<-rep(0,length(threshold))
R_square_test<-rep(0,length(threshold))
MSE_test<-rep(0,length(threshold))
MSE_train<-rep(0,length(threshold))
index<-1
list_nn<-list()
for (i in threshold){
set.seed(1234)
nn<-neuralnet(f,data=ner_scaled,hidden=15,linear.output=T,threshold = i)
#calculate R square
resp.train<-py.train$Adjusted.death_rate;pred.train<-compute(nn,ner_scaled)
SStotal<-var(resp.train)*(nrow(ner_scaled)-1)
SSE<-sum((resp.train-pred.train$net.result)^2)
SSR<-SStotal-SSE
R2<-SSR/SStotal
R_square_train[index]<-R2
MSE<-SSE/nrow(ner_scaled)
MSE_train[index]<-MSE
#test set
resp.test<-ner_scaled_test$`py.test$Adjusted.death_rate`;pred.test<-compute(nn,ner_scaled_test)
SStotal<-var(resp.test)*(nrow(ner_scaled_test)-1)
SSE<-sum((resp.test-pred.test$net.result)^2)
MSE<-SSE/nrow(ner_scaled_test)
MSE_test[index]<-MSE
SSR<-SStotal-SSE
R2_test<-SSR/SStotal
R_square_test[index]<-R2_test
index<-index+1
}
#show result
plot(R_square_train,sqrt(MSE_test),main ="R square in Training set vs standard variance in Test set",
xlab="R square",ylab = "Standard variance")
#choose R square==0.5888462 and standard variance==23.64915
setwd("/Users/mahaoxi/Desktop/competition/Useful dataset")
library(dplyr)     ##to do some data manipulation
library(data.table)##to read/write data in a fast way
#Import dataset
final<-fread('dataset_MODEL1.csv')
# Set Seed so that same sample can be reproduced in future also
set.seed(1234)
# Now Selecting 75% of data as sample from total 'n' rows of the data
sample <- sample.int(n = nrow(final), size = floor(.75*nrow(final)), replace = F)
train <- final[sample, ]
test  <- final[-sample, ]
write.csv(train,"train.csv")
write.csv(test,"test.csv")
train<-read.csv("train.csv")
test<-read.csv("test.csv")
py.train<-train[,c(5,4,6:18,21)]
py.test<-test[,c(5,4,6:18,21)]
#######neural network
library(neuralnet)
maxs <- apply(py.train[,c(2:16)], 2, max)
mins <- apply(py.train[,c(2:16)], 2, min)
data_scaled <- as.data.frame(scale(py.train[,c(2:16)], center = mins, scale = maxs - mins))
ner_scaled<-cbind(py.train$Adjusted.death_rate,data_scaled)
names(ner_scaled)[1]<-"Adjusted.death_rate"
data_scaled_test<- as.data.frame(scale(py.test[,c(2:16)], center = mins, scale = maxs - mins))
ner_scaled_test<-cbind(py.test$Adjusted.death_rate,data_scaled_test)
n<-names(ner_scaled)
f<-as.formula(paste("Adjusted.death_rate~",paste(n[!n %in% c("Adjusted.death_rate")],collapse="+")))
#choose different stopping criteria for nn
threshold<-seq(10,250,10)
R_square_train<-rep(0,length(threshold))
R_square_test<-rep(0,length(threshold))
MSE_test<-rep(0,length(threshold))
MSE_train<-rep(0,length(threshold))
index<-1
list_nn<-list()
for (i in threshold){
set.seed(1234)
nn<-neuralnet(f,data=ner_scaled,hidden=15,linear.output=T,threshold = i)
#calculate R square
resp.train<-py.train$Adjusted.death_rate;pred.train<-compute(nn,ner_scaled)
SStotal<-var(resp.train)*(nrow(ner_scaled)-1)
SSE<-sum((resp.train-pred.train$net.result)^2)
SSR<-SStotal-SSE
R2<-SSR/SStotal
R_square_train[index]<-R2
MSE<-SSE/nrow(ner_scaled)
MSE_train[index]<-MSE
#test set
resp.test<-ner_scaled_test$`py.test$Adjusted.death_rate`;pred.test<-compute(nn,ner_scaled_test)
SStotal<-var(resp.test)*(nrow(ner_scaled_test)-1)
SSE<-sum((resp.test-pred.test$net.result)^2)
MSE<-SSE/nrow(ner_scaled_test)
MSE_test[index]<-MSE
SSR<-SStotal-SSE
R2_test<-SSR/SStotal
R_square_test[index]<-R2_test
index<-index+1
}
#######neural network
library(neuralnet)
compute(nn,ner_scaled)
train<-read.csv("train.csv")
test<-read.csv("test.csv")
py.train<-train[,c(5,4,6:18,21)]
py.test<-test[,c(5,4,6:18,21)]
#######neural network
library(neuralnet)
maxs <- apply(py.train[,c(2:16)], 2, max)
mins <- apply(py.train[,c(2:16)], 2, min)
data_scaled <- as.data.frame(scale(py.train[,c(2:16)], center = mins, scale = maxs - mins))
ner_scaled<-cbind(py.train$Adjusted.death_rate,data_scaled)
names(ner_scaled)[1]<-"Adjusted.death_rate"
data_scaled_test<- as.data.frame(scale(py.test[,c(2:16)], center = mins, scale = maxs - mins))
ner_scaled_test<-cbind(py.test$Adjusted.death_rate,data_scaled_test)
n<-names(ner_scaled)
f<-as.formula(paste("Adjusted.death_rate~",paste(n[!n %in% c("Adjusted.death_rate")],collapse="+")))
threshold<-seq(10,250,10)
R_square_train<-rep(0,length(threshold))
R_square_test<-rep(0,length(threshold))
MSE_test<-rep(0,length(threshold))
MSE_train<-rep(0,length(threshold))
index<-1
list_nn<-list()
for (i in threshold){
set.seed(1234)
nn<-neuralnet(f,data=ner_scaled,hidden=15,linear.output=T,threshold = i)
#calculate R square
resp.train<-py.train$Adjusted.death_rate;pred.train<-compute(nn,ner_scaled)
SStotal<-var(resp.train)*(nrow(ner_scaled)-1)
SSE<-sum((resp.train-pred.train$net.result)^2)
SSR<-SStotal-SSE
R2<-SSR/SStotal
R_square_train[index]<-R2
MSE<-SSE/nrow(ner_scaled)
MSE_train[index]<-MSE
#test set
resp.test<-ner_scaled_test$`py.test$Adjusted.death_rate`;pred.test<-compute(nn,ner_scaled_test)
SStotal<-var(resp.test)*(nrow(ner_scaled_test)-1)
SSE<-sum((resp.test-pred.test$net.result)^2)
MSE<-SSE/nrow(ner_scaled_test)
MSE_test[index]<-MSE
SSR<-SStotal-SSE
R2_test<-SSR/SStotal
R_square_test[index]<-R2_test
index<-index+1
}
etwd("/Users/mahaoxi/Desktop/project/Insurance premiums")
library(mice)
library(neuralnet)
library(ggplot2)
data<-read.csv("insurance.csv",header=TRUE)
str(data)
#check NA value
md.pattern(data)
#scaled the data
maxs <- apply(data[,c(1,3,7)], 2, max)
mins <- apply(data[,c(1,3,7)], 2, min)
data_scaled <- as.data.frame(scale(data[,c(1,3,7)], center = mins, scale = maxs - mins))
#scale function give a matrix, we should transform into data.frame
data_scaled<-cbind(data_scaled,data[,c(2,4,5,6)])
data_scaled$female=ifelse((data$sex=="female"),1,0)
data_scaled$male=ifelse((data$sex=="male"),1,0)
data_scaled$childern0=ifelse((data$children==0),1,0)
data_scaled$childern1=ifelse((data$children==1),1,0)
data_scaled$childern2=ifelse((data$children==2),1,0)
data_scaled$childern3=ifelse((data$children==3),1,0)
data_scaled$childern4=ifelse((data$children==4),1,0)
data_scaled$childern5=ifelse((data$children==5),1,0)
data_scaled$smokeryes=ifelse((data$smoker=="yes"),1,0)
data_scaled$smokerno=ifelse((data$smoker=="no"),1,0)
data_scaled$region_ne<-ifelse((data$region=="northeast"),1,0)
data_scaled$region_nw<-ifelse((data$region=="northwest"),1,0)
data_scaled$region_se<-ifelse((data$region=="southeast"),1,0)
data_scaled$region_sw<-ifelse((data$region=="southwest"),1,0)
#divide data into two groups
set.seed(12345)
index<-sample(1:nrow(data_scaled),round(0.75*nrow(data_scaled)))
train<- data_scaled[index,]
test<- data_scaled[-index,]
train<-train[,-c(4:7)]
test<-test[,-c(4:7)]
#build neural net
n<-names(train)
f<-as.formula(paste("charges~",paste(n[!n %in% c("charges")],collapse="+")))
nn<-neuralnet(f,data=train,hidden=c(8,4),linear.output=T)
#plot(nn)
#calculate R^2
resp.train<-train$charges;pred.train<-compute(nn,train)
SStotal<-var(resp.train)*(nrow(train)-1)
SSE<-sum((resp.train-pred.train$net.result)^2)
SSR<-SStotal-SSE
R2<-SSR/SStotal
#For plot
resp.test<-test$charges;pred.test<-compute(nn,test)
fitted_value_test<-pred.test$net.result
attach(test)
test<-data.frame(charges=charges,id=seq(1:nrow(test)))
detach(test)
test_response_predict<-ggplot(test,aes(x=id))+geom_point(aes(y=charges),col=rgb(0,0,1,1/2))+
geom_line(aes(y=charges,col="yellow"))+
geom_point(aes(y=fitted_value_test),col=rgb(0,1,0,1/2))+
geom_line(aes(y=fitted_value_test,col="red"))+
labs(title="Response vs Fitted value in Test dataset",
subtitle="Using Neural net",y="Scaled charges")
plot(test_response_predict)
setwd("/Users/mahaoxi/Desktop/project/Insurance premiums")
library(mice)
library(neuralnet)
library(ggplot2)
data<-read.csv("insurance.csv",header=TRUE)
str(data)
md.pattern(data)
#scaled the data
maxs <- apply(data[,c(1,3,7)], 2, max)
mins <- apply(data[,c(1,3,7)], 2, min)
data_scaled <- as.data.frame(scale(data[,c(1,3,7)], center = mins, scale = maxs - mins))
#scale function give a matrix, we should transform into data.frame
data_scaled<-cbind(data_scaled,data[,c(2,4,5,6)])
data_scaled$female=ifelse((data$sex=="female"),1,0)
data_scaled$male=ifelse((data$sex=="male"),1,0)
data_scaled$childern0=ifelse((data$children==0),1,0)
data_scaled$childern1=ifelse((data$children==1),1,0)
data_scaled$childern2=ifelse((data$children==2),1,0)
data_scaled$childern3=ifelse((data$children==3),1,0)
data_scaled$childern4=ifelse((data$children==4),1,0)
data_scaled$childern5=ifelse((data$children==5),1,0)
data_scaled$smokeryes=ifelse((data$smoker=="yes"),1,0)
data_scaled$smokerno=ifelse((data$smoker=="no"),1,0)
data_scaled$region_ne<-ifelse((data$region=="northeast"),1,0)
data_scaled$region_nw<-ifelse((data$region=="northwest"),1,0)
data_scaled$region_se<-ifelse((data$region=="southeast"),1,0)
data_scaled$region_sw<-ifelse((data$region=="southwest"),1,0)
set.seed(12345)
index<-sample(1:nrow(data_scaled),round(0.75*nrow(data_scaled)))
train<- data_scaled[index,]
test<- data_scaled[-index,]
train<-train[,-c(4:7)]
test<-test[,-c(4:7)]
#build neural net
n<-names(train)
f<-as.formula(paste("charges~",paste(n[!n %in% c("charges")],collapse="+")))
nn<-neuralnet(f,data=train,hidden=c(8,4),linear.output=T)
#plot(nn)
#calculate R^2
resp.train<-train$charges;pred.train<-compute(nn,train)
SStotal<-var(resp.train)*(nrow(train)-1)
SSE<-sum((resp.train-pred.train$net.result)^2)
SSR<-SStotal-SSE
R2<-SSR/SStotal
#For plot
resp.test<-test$charges;pred.test<-compute(nn,test)
fitted_value_test<-pred.test$net.result
attach(test)
test<-data.frame(charges=charges,id=seq(1:nrow(test)))
detach(test)
test_response_predict<-ggplot(test,aes(x=id))+geom_point(aes(y=charges),col=rgb(0,0,1,1/2))+
geom_line(aes(y=charges,col="yellow"))+
geom_point(aes(y=fitted_value_test),col=rgb(0,1,0,1/2))+
geom_line(aes(y=fitted_value_test,col="red"))+
labs(title="Response vs Fitted value in Test dataset",
subtitle="Using Neural net",y="Scaled charges")
plot(test_response_predict)
