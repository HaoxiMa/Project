#=====EXPLORATORY DATA ANALYSIS
#Learning curve
#for convenience, we use python to plot
#according to the learning curves, we do not need to add polynomial features
#Check the skewness of response
table(train_set$Buy)
#skewness exists, so we will not use accuracy to test
#Check multicollinearity
check_model<-glm(Buy~.,data=train_set,family = "binomial")
vif(check_model)>5
#no muliticollinearity, but we still to do model selection to delete redundant variables
###Use Lasso regression to do model selection
#set up the matrix
x<-model.matrix(Buy~.,data=train_set)[,-1]
y<-as.numeric(as.character(train_set$Buy))
# Find the best lambda using cross-validation
set.seed(1)
cv <- cv.glmnet(x, y, alpha = 1)#alpha=1 means lasso and 0 means riged
cv$lambda.min #give lamda that shows the samllest deviance model
#cv$lambda.1se   give lamda that show the simpliest model
#Do lasso regression
model_select <- glmnet(x, y, alpha = 1, lambda = cv$lambda.min)
coef(model_select)
#get the formula
lasso_formula<-as.formula(Buy~Income+Is.Female+Dual.Income+Minors+Own+House+
White+Prev.Child.Mag+Prev.Parent.Mag)
###Using AIC to select the "best" model
k<-stepAIC(check_model)
###Compare two selected models
fit1<-glm(k$formula,data=train_set,family = "binomial")
fit2<-glm(lasso_formula,data=train_set,family = "binomial")
summary(fit1);summary(fit2)
###Using ROC plot to help choose model
#model1
pred_check1<-prediction(fitted(fit1),train_set$Buy)
perf_check1<-performance(pred_check1,"tpr","fpr")
plot(perf_check1,main="ROC plot for Model2");abline(0,1)
roc_area1<-roc.area(as.numeric(as.character(train_set$Buy)),fitted(fit1))#area under roc plot
roc_area1$A
#model2
pred_check2<-prediction(fitted(fit2),train_set$Buy)
perf_check2<-performance(pred_check2,"tpr","fpr")
plot(perf_check2,main="ROC plot for Model1");abline(0,1)
roc_area2<-roc.area(as.numeric(as.character(train_set$Buy)),fitted(fit2))#area under roc plot
roc_area2$A
#According to Principle of Parsimony, we will choose the fit1 model
final_formula<-k$formula
#update the train and test dataset
train_set<-train_set[,c("Buy","Income","Is.Female","Minors","Own","White","English",
"Prev.Child.Mag","Prev.Parent.Mag")]
test_set<-test_set[,c("Buy","Income","Is.Female","Minors","Own","White","English",
"Prev.Child.Mag","Prev.Parent.Mag")]
###Logistic regression
#Fit the model
logistic_classifier<-glm(final_formula,data=train_set,family = "binomial")
summary(logistic_classifier)
#plot the residuals
#deviance residual
deviance_res<-residuals(logistic_classifier,type="deviance")
plot(deviance_res,main="Plot for deviance residuals",xlab="Index",ylab="Deviance Residuals")
#Pearson residuals
pearson_res<-residuals(logistic_classifier,type="pearson")
plot(pearson_res,main="Plot for Pearson residuals",xlab="Index",ylab="Pearson Residual")
#check the goodness of fit
y_goodness<-as.numeric(as.character(train_set$Buy))
hoslem.test(y_goodness,fitted(logistic_classifier),g=10)
#very excellent
#selet the best cut off based on test dataset
y_select_pred<-predict(logistic_classifier,test_set,type="response")
select_cut_dataset<-data.frame("predict"=y_select_pred,
"actual"=as.numeric(as.character(test_set$Buy)))
c<-seq(0.2,0.8,0.05)
accuracy<-c()
j=1
for (i in c){
y_judge<-ifelse(select_cut_dataset$predict>i,1,0)
cm <-table(y_judge,select_cut_dataset$actual)
accuracy_i<-(cm[1,1]+cm[2,2])/(cm[1,1]+cm[1,2]+cm[2,1]+cm[2,2])
accuracy[j]<-accuracy_i
j<-j+1
}
plot_data<-data.frame(c,accuracy)
gg_cut<-ggplot(plot_data,aes(x=c,y=accuracy))+geom_line(size=1,color=rgb(0,0,1,1/2))+
labs(title="Accuracy vs Cut off",y="Accuracy",x="Cut off")
plot(gg_cut)
#Consider that it's important to get the people who will buy, then we will choose 0.5 as cut off
#Calculate the F1 score for Logistic regression
y_pred_logistic<-ifelse(select_cut_dataset$predict>0.5,1,0)
cm1 <-table(y_pred_logistic,select_cut_dataset$actual)
cm1;
P_logistic<-cm1[1,1]/(cm1[1,1]+cm1[1,2])#precision
R_logistic<-cm1[1,1]/(cm1[1,1]+cm1[2,1])#recall
F1_score_logistic<-(2*P_logistic*R_logistic)/(P_logistic+R_logistic)
F1_score_logistic
###SVM
#becasue #features is small and #observations is intermediate, we choose to use Gaussian kernel
#Using grid search to get the optimal parameters
set.seed(12345)
grid_search<-train(Buy~.,data=train_set,method="svmRadial")
grid_search
grid_search$bestTune
#Fit a SVM classifier
#gamma is sigma
gammaa<-as.numeric(grid_search$bestTune[1])
SVM_classifier<-svm(Buy~.,data=train_set,type="C-classification",kernel="radial",
cost=1,gamma=gammaa,probability=T)
summary(SVM_classifier)
plot(SVM_classifier,train_set)
plot(SVM_classifier,train_set)
plot(SVM_classifier,train_set,Buy~.)
print(SVM_classifier)
setwd("/Users/mahaoxi/Desktop/Machine Learning/ML in Python and R/Classification/Logistic")
dataset<-read.csv("Social_Network_Ads.csv")
dataset
#Fitting logistic regression to training set
classifier<-glm(Purchased~.,family=binomial,data=training_set)
setwd("/Users/mahaoxi/Desktop/Machine Learning/ML in Python and R/Classification/Logistic")
dataset<-read.csv("Social_Network_Ads.csv")
dataset<-dataset[,3:5]
library(caTools)
set.seed(123)
Split<-sample.split(dataset$Purchased,SplitRatio = 0.75)
training_set<-subset(dataset,Split == TRUE)
test_set<-subset(dataset,Split ==FALSE)
#Feature Scaling
maxs <- apply(training_set[,c(1,2)], 2, max)
mins <- apply(training_set[,c(1,2)], 2, min)
training_set[,c(1,2)]<- scale(training_set[,c(1,2)], center = mins, scale = maxs - mins)
test_set[,c(1,2)]<- scale(test_set[,c(1,2)], center =  mins, scale = maxs - mins)
#Fitting logistic regression to training set
classifier<-glm(Purchased~.,family=binomial,data=training_set)
summary(classifier)
SVM_classifier
SVM_classifier$decision.values
SVM_classifier$x.scale
SVM_classifier<-svm(Buy~.,data=train_set,type="C-classification",kernel="radial",
cost=1,gamma=gammaa,probability=T,scale = F)
summary(SVM_classifier)
y_pred_SVM<-predict(SVM_classifier,test_set[,-1])
cm2 <-table(y_pred_SVM,test_set$Buy)
cm2;
P_SVM<-cm2[1,1]/(cm2[1,1]+cm2[1,2])#precision
R_SVM<-cm2[1,1]/(cm2[1,1]+cm2[2,1])#recall
F1_score_SVM<-(2*P_SVM*R_SVM)/(P_SVM+R_SVM)
F1_score_SVM
y_pred_SVM<-predict(SVM_classifier,test_set[,-1])
cm2 <-table(y_pred_SVM,test_set$Buy)
cm2;
P_SVM<-cm2[1,1]/(cm2[1,1]+cm2[1,2])#precision
R_SVM<-cm2[1,1]/(cm2[1,1]+cm2[2,1])#recall
F1_score_SVM<-(2*P_SVM*R_SVM)/(P_SVM+R_SVM)
F1_score_SVM
#=======Decision of Advertising Strategy Using Machine Learning Methods=====
#Import useful packages
library(mice) # Data mining
library(tidyverse) #Data manipulate
library(caTools) #Split dataset
library(caret) #Machine learning
library(glmnet) #penalized regression
library(caret) #diagnose for regression
library(car) #diagnose for regression
library(ResourceSelection) #hoslem.test
library(ROCR) #ROC plot
library(verification) #area under ROC plot
library(ggplot2) #plot
library(e1071) #SVM
library(randomForest) #randomforest
library(h2o) #ANN
#Change path
setwd("/Users/mahaoxi/Desktop/5637/project")
#=====DATA PROCESSING=====
#Import data
data<-read.csv("KidCreative.csv")
data<-data[,-1]
#Checking missing value
md.pattern(data)
#Encoding the categorical variables
str(data)
iter<-c(1,3:8,10:17)
for (i in iter){
data[,i]<-factor(data[,i])
}
str(data)
#Splitting the dataset into train and test dataset
set.seed(1234)
Split<-sample.split(data$Buy,SplitRatio = 0.8)
train_set<-subset(data,Split == TRUE)
test_set<-subset(data,Split ==FALSE)
#Feature Scaling
maxs <- apply(train_set[,c(2,9)], 2, max)
mins <- apply(train_set[,c(2,9)], 2, min)
train_set[,c(2,9)]<- scale(train_set[,c(2,9)], center = mins, scale = maxs - mins)
test_set[,c(2,9)]<- scale(test_set[,c(2,9)], center = mins, scale = maxs - mins)
#Output the train set for plot learning curves in python
write.table(train_set,file="training_set.txt",sep=",")
write.table(test_set,file="test_set.txt",sep=",")
#=====EXPLORATORY DATA ANALYSIS
#Learning curve
#for convenience, we use python to plot
#according to the learning curves, we do not need to add polynomial features
#Check the skewness of response
table(train_set$Buy)
#skewness exists, so we will not use accuracy to test
#Check multicollinearity
check_model<-glm(Buy~.,data=train_set,family = "binomial")
vif(check_model)>5
#no muliticollinearity, but we still to do model selection to delete redundant variables
###Use Lasso regression to do model selection
#set up the matrix
x<-model.matrix(Buy~.,data=train_set)[,-1]
y<-as.numeric(as.character(train_set$Buy))
# Find the best lambda using cross-validation
set.seed(1)
cv <- cv.glmnet(x, y, alpha = 1)#alpha=1 means lasso and 0 means riged
cv$lambda.min #give lamda that shows the samllest deviance model
#cv$lambda.1se   give lamda that show the simpliest model
#Do lasso regression
model_select <- glmnet(x, y, alpha = 1, lambda = cv$lambda.min)
coef(model_select)
#get the formula
lasso_formula<-as.formula(Buy~Income+Is.Female+Dual.Income+Minors+Own+House+
White+Prev.Child.Mag+Prev.Parent.Mag)
###Using AIC to select the "best" model
k<-stepAIC(check_model)
###Compare two selected models
fit1<-glm(k$formula,data=train_set,family = "binomial")
fit2<-glm(lasso_formula,data=train_set,family = "binomial")
summary(fit1);summary(fit2)
###Using ROC plot to help choose model
#model1
pred_check1<-prediction(fitted(fit1),train_set$Buy)
perf_check1<-performance(pred_check1,"tpr","fpr")
plot(perf_check1,main="ROC plot for Model2");abline(0,1)
roc_area1<-roc.area(as.numeric(as.character(train_set$Buy)),fitted(fit1))#area under roc plot
roc_area1$A
#model2
pred_check2<-prediction(fitted(fit2),train_set$Buy)
perf_check2<-performance(pred_check2,"tpr","fpr")
plot(perf_check2,main="ROC plot for Model1");abline(0,1)
roc_area2<-roc.area(as.numeric(as.character(train_set$Buy)),fitted(fit2))#area under roc plot
roc_area2$A
#According to Principle of Parsimony, we will choose the fit1 model
final_formula<-k$formula
#update the train and test dataset
train_set<-train_set[,c("Buy","Income","Is.Female","Minors","Own","White","English",
"Prev.Child.Mag","Prev.Parent.Mag")]
test_set<-test_set[,c("Buy","Income","Is.Female","Minors","Own","White","English",
"Prev.Child.Mag","Prev.Parent.Mag")]
###Logistic regression
#Fit the model
logistic_classifier<-glm(final_formula,data=train_set,family = "binomial")
summary(logistic_classifier)
#plot the residuals
#deviance residual
deviance_res<-residuals(logistic_classifier,type="deviance")
plot(deviance_res,main="Plot for deviance residuals",xlab="Index",ylab="Deviance Residuals")
#Pearson residuals
pearson_res<-residuals(logistic_classifier,type="pearson")
plot(pearson_res,main="Plot for Pearson residuals",xlab="Index",ylab="Pearson Residual")
#check the goodness of fit
y_goodness<-as.numeric(as.character(train_set$Buy))
hoslem.test(y_goodness,fitted(logistic_classifier),g=10)
#very excellent
#selet the best cut off based on test dataset
y_select_pred<-predict(logistic_classifier,test_set,type="response")
select_cut_dataset<-data.frame("predict"=y_select_pred,
"actual"=as.numeric(as.character(test_set$Buy)))
c<-seq(0.2,0.8,0.05)
accuracy<-c()
j=1
for (i in c){
y_judge<-ifelse(select_cut_dataset$predict>i,1,0)
cm <-table(y_judge,select_cut_dataset$actual)
accuracy_i<-(cm[1,1]+cm[2,2])/(cm[1,1]+cm[1,2]+cm[2,1]+cm[2,2])
accuracy[j]<-accuracy_i
j<-j+1
}
plot_data<-data.frame(c,accuracy)
gg_cut<-ggplot(plot_data,aes(x=c,y=accuracy))+geom_line(size=1,color=rgb(0,0,1,1/2))+
labs(title="Accuracy vs Cut off",y="Accuracy",x="Cut off")
plot(gg_cut)
#Consider that it's important to get the people who will buy, then we will choose 0.5 as cut off
#Calculate the F1 score for Logistic regression
y_pred_logistic<-ifelse(select_cut_dataset$predict>0.5,1,0)
cm1 <-table(y_pred_logistic,select_cut_dataset$actual)
cm1;
P_logistic<-cm1[1,1]/(cm1[1,1]+cm1[1,2])#precision
R_logistic<-cm1[1,1]/(cm1[1,1]+cm1[2,1])#recall
F1_score_logistic<-(2*P_logistic*R_logistic)/(P_logistic+R_logistic)
F1_score_logistic
###SVM
#becasue #features is small and #observations is intermediate, we choose to use Gaussian kernel
#Using grid search to get the optimal parameters
set.seed(12345)
grid_search<-train(Buy~.,data=train_set,method="svmRadial")
grid_search
grid_search$bestTune
#Fit a SVM classifier
#gamma is sigma
gammaa<-as.numeric(grid_search$bestTune[1])
SVM_classifier<-svm(Buy~.,data=train_set,type="C-classification",kernel="radial",
cost=1,gamma=gammaa,probability=T,scale = F)
summary(SVM_classifier)
summary(SVM_classifier)
#Calculate the F1 score for SVM
#y_pred_SVM<-predict(SVM_classifier,test_set[,-1],probability = T)
y_pred_SVM<-predict(SVM_classifier,test_set[,-1])
cm2 <-table(y_pred_SVM,test_set$Buy)
cm2;
P_SVM<-cm2[1,1]/(cm2[1,1]+cm2[1,2])#precision
R_SVM<-cm2[1,1]/(cm2[1,1]+cm2[2,1])#recall
F1_score_SVM<-(2*P_SVM*R_SVM)/(P_SVM+R_SVM)
F1_score_SVM
gammaa<-as.numeric(grid_search$bestTune[1])
SVM_classifier<-svm(Buy~.,data=train_set,type="C-classification",kernel="radial",
cost=1,gamma=gammaa,probability=T,scale = T)
summary(SVM_classifier)
#y_pred_SVM<-predict(SVM_classifier,test_set[,-1],probability = T)
y_pred_SVM<-predict(SVM_classifier,test_set[,-1])
cm2 <-table(y_pred_SVM,test_set$Buy)
cm2;
P_SVM<-cm2[1,1]/(cm2[1,1]+cm2[1,2])#precision
R_SVM<-cm2[1,1]/(cm2[1,1]+cm2[2,1])#recall
F1_score_SVM<-(2*P_SVM*R_SVM)/(P_SVM+R_SVM)
F1_score_SVM
accuracy<-c()
j=1
for (i in c){
y_judge<-ifelse(select_cut_dataset$predict>i,1,0)
cm <-table(y_judge,select_cut_dataset$actual)
accuracy_i<-(cm[1,1]+cm[2,2])/(cm[1,1]+cm[1,2]+cm[2,1]+cm[2,2])
accuracy[j]<-accuracy_i
j<-j+1
}
plot_data<-data.frame(c,accuracy)
gg_cut<-ggplot(plot_data,aes(x=c,y=accuracy))+geom_line(size=1,color=rgb(0,0,1,1/2))+
labs(title="Accuracy vs Cut off",y="Accuracy",x="Cut off")
plot(gg_cut)
#Consider that it's important to get the people who will buy, then we will choose 0.5 as cut off
#Calculate the F1 score for Logistic regression
y_pred_logistic<-ifelse(select_cut_dataset$predict>0.5,1,0)
cm1 <-table(y_pred_logistic,select_cut_dataset$actual)
cm1;
P_logistic<-cm1[1,1]/(cm1[1,1]+cm1[1,2])#precision
R_logistic<-cm1[1,1]/(cm1[1,1]+cm1[2,1])#recall
F1_score_logistic<-(2*P_logistic*R_logistic)/(P_logistic+R_logistic)
F1_score_logistic
###SVM
#becasue #features is small and #observations is intermediate, we choose to use Gaussian kernel
#Using grid search to get the optimal parameters
set.seed(12345)
grid_search<-train(Buy~.,data=train_set,method="svmRadial")
grid_search
grid_search$bestTune
#Fit a SVM classifier
#gamma is sigma
gammaa<-as.numeric(grid_search$bestTune[1])
SVM_classifier<-svm(Buy~.,data=train_set,type="C-classification",kernel="radial",
cost=1,gamma=gammaa,probability=T,scale = T)
summary(SVM_classifier)
#Calculate the F1 score for SVM
#y_pred_SVM<-predict(SVM_classifier,test_set[,-1],probability = T)
y_pred_SVM<-predict(SVM_classifier,test_set[,-1])
cm2 <-table(y_pred_SVM,test_set$Buy)
cm2;
P_SVM<-cm2[1,1]/(cm2[1,1]+cm2[1,2])#precision
R_SVM<-cm2[1,1]/(cm2[1,1]+cm2[2,1])#recall
F1_score_SVM<-(2*P_SVM*R_SVM)/(P_SVM+R_SVM)
F1_score_SVM
###Naive Bayes
#Fit a Naive Bayes classifier
str(train_set)
NB_classifier<-naiveBayes(x = train_set[,-1],y = train_set[,1])
#Calculate the F1 score for Naive Bayes
y_pred_NB<-predict(NB_classifier,test_set[,-1])
cm3 <-table(y_pred_NB,test_set$Buy)
cm3;
P_NB<-cm3[1,1]/(cm3[1,1]+cm3[1,2])#precision
R_NB<-cm3[1,1]/(cm3[1,1]+cm3[2,1])#recall
F1_score_NB<-(2*P_NB*R_NB)/(P_NB+R_NB)
F1_score_NB
###Random forest
#grid search to get the optimal parameters
set.seed(123456)
grid_search2<-train(Buy~.,data=train_set,method="rf")
grid_search2
grid_search2$bestTune
#Fit a randomforest classifier
set.seed(1234567)
mtry<-as.numeric(grid_search2$bestTune[1])
RF_classifier<-randomForest(x = train_set[,-1],y = train_set[,1],ntree=50,mtry = mtry)
#Calculate the F1 score for Random forest
y_pred_RF<-predict(RF_classifier,test_set[,-1])
cm4 <-table(y_pred_RF,test_set$Buy)
cm4;
P_RF<-cm4[1,1]/(cm4[1,1]+cm4[1,2])#precision
R_RF<-cm4[1,1]/(cm4[1,1]+cm4[2,1])#recall
F1_score_RF<-(2*P_RF*R_RF)/(P_RF+R_RF)
F1_score_RF
###Artifical NN
#Build ANN for train set
h2o.init(nthreads = -1 )#Connect to H20 并且用所有的计算机核并行计算
ANN_classifier<-h2o.deeplearning(y="Buy",training_frame = as.h2o(train_set),activation = "Rectifier",
hidden = c(6,6),epochs = 100,train_samples_per_iteration = -2)
plot(RF_classifier)
plot(NB_classifier)
plot(ANN_classifier)
summary(SVM_classifier)
nrow(train_set)
cm2;
F1_score_SVM
str(train_set)
NB_classifier<-naiveBayes(x = train_set[,-1],y = train_set[,1])
#Calculate the F1 score for Naive Bayes
y_pred_NB<-predict(NB_classifier,test_set[,-1])
cm3 <-table(y_pred_NB,test_set$Buy)
cm3;
P_NB<-cm3[1,1]/(cm3[1,1]+cm3[1,2])#precision
R_NB<-cm3[1,1]/(cm3[1,1]+cm3[2,1])#recall
F1_score_NB<-(2*P_NB*R_NB)/(P_NB+R_NB)
F1_score_NB
F1_score_NB
grid_search2$bestTune
RF_classifier
varImpPlot(RF_classifier,main="Variable importance")
y_pred_RF<-predict(RF_classifier,test_set[,-1])
cm4 <-table(y_pred_RF,test_set$Buy)
cm4;
P_RF<-cm4[1,1]/(cm4[1,1]+cm4[1,2])#precision
R_RF<-cm4[1,1]/(cm4[1,1]+cm4[2,1])#recall
F1_score_RF<-(2*P_RF*R_RF)/(P_RF+R_RF)
F1_score_RF
h2o.init(nthreads = -1 )#Connect to H20 并且用所有的计算机核并行计算
ANN_classifier<-h2o.deeplearning(y="Buy",training_frame = as.h2o(train_set),activation = "Rectifier",
hidden = c(8,4),epochs = 100,train_samples_per_iteration = -2)
#Predicting the test set results
y_prob_ANN<-h2o.predict(ANN_classifier,newdata=as.h2o(test_set))
y_pred_ANN<-as.data.frame(y_prob_ANN)
y_pred_ANN<-y_pred_ANN$predict
#Calculate the F1 score for ANN
cm5 <-table(y_pred_ANN,test_set$Buy)
cm5;
P_ANN<-cm5[1,1]/(cm5[1,1]+cm5[1,2])#precision
R_ANN<-cm5[1,1]/(cm5[1,1]+cm5[2,1])#recall
F1_score_ANN<-(2*P_ANN*R_ANN)/(P_ANN+R_ANN)
F1_score_ANN
h2o.init(nthreads = -1 )#Connect to H20 并且用所有的计算机核并行计算
ANN_classifier<-h2o.deeplearning(y="Buy",training_frame = as.h2o(train_set),activation = "Rectifier",
hidden = c(8,8,4),epochs = 100,train_samples_per_iteration = -2)
#Predicting the test set results
y_prob_ANN<-h2o.predict(ANN_classifier,newdata=as.h2o(test_set))
y_pred_ANN<-as.data.frame(y_prob_ANN)
y_pred_ANN<-y_pred_ANN$predict
#Calculate the F1 score for ANN
cm5 <-table(y_pred_ANN,test_set$Buy)
cm5;
P_ANN<-cm5[1,1]/(cm5[1,1]+cm5[1,2])#precision
R_ANN<-cm5[1,1]/(cm5[1,1]+cm5[2,1])#recall
F1_score_ANN<-(2*P_ANN*R_ANN)/(P_ANN+R_ANN)
F1_score_ANN
h2o.init(nthreads = -1 )#Connect to H20 并且用所有的计算机核并行计算
ANN_classifier<-h2o.deeplearning(y="Buy",training_frame = as.h2o(train_set),activation = "Rectifier",
hidden = c(8,8),epochs = 100,train_samples_per_iteration = -2)
#Predicting the test set results
y_prob_ANN<-h2o.predict(ANN_classifier,newdata=as.h2o(test_set))
y_pred_ANN<-as.data.frame(y_prob_ANN)
y_pred_ANN<-y_pred_ANN$predict
#Calculate the F1 score for ANN
cm5 <-table(y_pred_ANN,test_set$Buy)
cm5;
P_ANN<-cm5[1,1]/(cm5[1,1]+cm5[1,2])#precision
R_ANN<-cm5[1,1]/(cm5[1,1]+cm5[2,1])#recall
F1_score_ANN<-(2*P_ANN*R_ANN)/(P_ANN+R_ANN)
F1_score_ANN
h2o.init(nthreads = -1 )#Connect to H20 并且用所有的计算机核并行计算
ANN_classifier<-h2o.deeplearning(y="Buy",training_frame = as.h2o(train_set),activation = "Rectifier",
hidden = c(8,4),epochs = 100,train_samples_per_iteration = -2)
#Predicting the test set results
y_prob_ANN<-h2o.predict(ANN_classifier,newdata=as.h2o(test_set))
y_pred_ANN<-as.data.frame(y_prob_ANN)
y_pred_ANN<-y_pred_ANN$predict
#Calculate the F1 score for ANN
cm5 <-table(y_pred_ANN,test_set$Buy)
cm5;
P_ANN<-cm5[1,1]/(cm5[1,1]+cm5[1,2])#precision
R_ANN<-cm5[1,1]/(cm5[1,1]+cm5[2,1])#recall
F1_score_ANN<-(2*P_ANN*R_ANN)/(P_ANN+R_ANN)
F1_score_ANN
F1_score_ANN
ML_names<-c("Logistic Regression","SVM with Gaussian Kernel","Naive Bayes",
"Random Forest","Artificial Neural Network")
F1_score<-c(F1_score_logistic,F1_score_SVM,F1_score_NB,F1_score_RF,F1_score_ANN)
Fianl_summary<-data.frame(ML_names,F1_score)
View(Fianl_summary)
data[,c(2,9)]<- scale(data[,c(2,9)], center = mins, scale = maxs - mins)
data<-data[,c("Buy","Income","Is.Female","Minors","Own","White","English",
"Prev.Child.Mag","Prev.Parent.Mag")]
folds<-createFolds(data$Buy,k=10)#把数据分成10块
cv<-lapply(folds,function(x){
training_fold<-data[-x,]
test_fold<-data[x,]
grid_search<-train(Buy~.,data=training_fold,method="svmRadial")
Cost<-as.numeric(grid_search$bestTune[2])
Gramma<-as.numeric(grid_search$bestTune[1])
classifier<-svm(Buy~.,data=training_fold,type="C-classification",kernel="radial",
cost=Cost,gamma=Gramma)
y_pred<-predict(classifier,test_fold[,-1])
cm <-table(test_fold$Buy,y_pred)
accuracy<-(cm[1,1]+cm[2,2])/(cm[1,1]+cm[1,2]+cm[2,1]+cm[2,2])
return(accuracy)
})
mean(as.numeric(cv))
